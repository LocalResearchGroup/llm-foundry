icl_tasks:
-
  label: hellaswag
  dataset_uri: eval/local_data/language_understanding/hellaswag.jsonl
  num_fewshot: [0]
  icl_task_type: multiple_choice

-
  label: arc_easy
  dataset_uri: eval/local_data/world_knowledge/arc_easy.jsonl
  num_fewshot: [0]
  icl_task_type: multiple_choice
  continuation_delimiter: "\nAnswer: "

-
  label: arc_challenge
  dataset_uri: eval/local_data/world_knowledge/arc_challenge.jsonl
  num_fewshot: [0]
  icl_task_type: multiple_choice
  continuation_delimiter: "\nAnswer: "

-
  label: piqa
  dataset_uri: eval/local_data/commonsense_reasoning/piqa.jsonl
  num_fewshot: [0]
  icl_task_type: multiple_choice
  continuation_delimiter: "\nAnswer: "

-
  label: mmlu
  dataset_uri: eval/local_data/world_knowledge/mmlu.jsonl
  num_fewshot: [0]
  icl_task_type: multiple_choice
  continuation_delimiter: "\nAnswer: "
  has_categories: true

-
  label: commonsense_qa
  dataset_uri: eval/local_data/commonsense_reasoning/commonsense_qa.jsonl
  num_fewshot: [0]
  icl_task_type: multiple_choice

-
  label: triviaqa_sm
  dataset_uri: eval/local_data/world_knowledge/triviaqa_sm.jsonl
  num_fewshot: [0]
  icl_task_type: generation_task_with_answers
  do_normalization: true

-
  label: winogrande
  dataset_uri: eval/local_data/language_understanding/winogrande.jsonl
  num_fewshot: [0]
  icl_task_type: schema

-
  label: openbook_qa
  dataset_uri: eval/local_data/commonsense_reasoning/openbook_qa.jsonl
  num_fewshot: [0]
  icl_task_type: multiple_choice

-
  label: gsm8k
  dataset_uri: eval/local_data/symbolic_problem_solving/gsm8k.jsonl
  num_fewshot: [5]
  icl_task_type: generation_task_with_answers
  cot_delimiter: "The answer is "
  continuation_delimiter: "\n\nA:"
  question_prelimiter: ""
  do_normalization: false
  early_stopping_criteria:
  - "\n\n"
  - "Question:"